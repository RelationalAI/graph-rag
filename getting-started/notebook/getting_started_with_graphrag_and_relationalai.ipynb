{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4146a83-0890-47db-a6e6-3b5f7c7e0e48",
   "metadata": {},
   "source": [
    "![RelationalAI - Getting started with GraphRAG](assets/header.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a53e4c-6415-4482-b122-e54f6218fa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import relationalai as rai\n",
    "from relationalai.clients.snowflake import Session, Snowflake\n",
    "from relationalai.std import aggregates, alias\n",
    "from relationalai.std.graphs import Graph\n",
    "\n",
    "# Solution packages.\n",
    "sys.path.append(\"../python/src/\")\n",
    "\n",
    "from sf_rai_graphrag.rai import *\n",
    "from sf_rai_graphrag.snowflake import *\n",
    "from sf_rai_graphrag.util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4be1913-9c07-4084-89d0-bced21397ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5bfc90-7ff9-4a5c-8566-547d0e5c0ae0",
   "metadata": {},
   "source": [
    "## Snowflake session setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94154941-21e5-4b9a-b59a-06702d5b922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session.builder.configs({\n",
    "    \"user\": \"<your_snowflake_username>\", \n",
    "    \"password\": \"<your_snowflake_password>\", \n",
    "    \"account\": \"<your_snowflake_account_identifier>\", \n",
    "    \"database\": \"graph_rag\", \n",
    "    \"schema\": \"graph_rag\", \n",
    "    \"role\": \"accountadmin\", \n",
    "    \"warehouse=\": \"graph_rag\"\n",
    "}).create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4901351c-3be7-47b2-988c-74a4e4634ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.use_role(\"accountadmin\")\n",
    "session.use_database(\"graph_rag\")\n",
    "session.use_schema(\"graph_rag\")\n",
    "session.use_warehouse(\"graph_rag\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e47b986-b038-43b4-a247-7057695a11f1",
   "metadata": {},
   "source": [
    "## Creating a graph with the RelationalAI Native App"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a334a1-c4b4-40ae-b4ac-7ddc3c7d4d4a",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "\n",
    "- The [RelationalAI Native App](https://app.snowflake.com/marketplace/listing/GZTYZOOIX8H/relationalai-relationalai?search=relationalai&originTab=provider&providerName=RelationalAI&profileGlobalName=GZTYZOOIX7W) **must have been installed** in the Snowflake account being used.\n",
    "- The [RelationalAI CLI](https://relational.ai/docs/reference/cli/) **must have been installed**.\n",
    "- A `raiconfig.toml` must be present in the project root. To create a `raiconfig.toml` execute `rai init` in the project root and provide the required information. More info on the [RelationalAI CLI reference](https://relational.ai/docs/reference/cli/) page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02af0eb-7d92-4198-a565-dfda178fb601",
   "metadata": {},
   "source": [
    "Creating the RelationalAI resources required can either be done either with the use of the CLI or by the functions provided in this notebook, for convenience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1a36fa-349e-4748-ad20-8a4eaca87fa2",
   "metadata": {},
   "source": [
    "### Manual resource provisioning\n",
    "\n",
    "- Provision a RAI engine by executing `rai engines:create` in the project root and providing the required information.\n",
    "  \n",
    "- Setup the Snowflake - RelationalAI Data Streams:\n",
    "    - `rai imports:stream --source graph_rag.graph_rag.nodes --model graph_rag`\n",
    "    - `rai imports:stream --source graph_rag.graph_rag.edges --model graph_rag`\n",
    "\n",
    "Having submitted the streams, we should wait for the data to synchronize by checking that the status is `LOADED` for both. Checking the lifecycle stage of the streams creation is performed by issuing the following CLI command:\n",
    "\n",
    "- `rai imports:list --model graph_rag`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1bf474-0f80-4522-bca7-6c5a9a985f20",
   "metadata": {},
   "source": [
    "### Automatic resource provisioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cd1f76-7d03-4f68-bc76-8a9870ff3f20",
   "metadata": {},
   "source": [
    "#### Provisioning a RelationalAI engine\n",
    "\n",
    "The following convenience function wraps the `rai engines:create` CLI command.\n",
    "\n",
    "Note: the `engine_size` and `engine_pool` values can be retrieved with by following the manual `rai engines:create` and taking note of the `Engine size` and `Compute pool` prompt options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a214ff-e18c-4a42-9f0c-fbb399f6ea78",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Note: this process takes a few minutes to complete if a new engine must be provisioned.\n",
    "output = create_engine(\n",
    "    config={\n",
    "        \"engine\": \"graph_rag\", \n",
    "        \"engine_size\": \"<your_engine_size>\", \n",
    "        \"engine_pool\": \"<your_engine_pool>\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68637fa2-c12d-4ec5-b038-24ab77fb39ab",
   "metadata": {},
   "source": [
    "#### Provisioning Data Streams\n",
    "\n",
    "The following convenience function wraps `rai imports:stream --source graph_rag.graph_rag.nodes --model graph_rag` and `rai imports:stream --source graph_rag.graph_rag.edges --model graph_rag` CLI commands to create the Data Streams. Also, it blocks until both Data Streams are in `LOADED` status. `2` streams must be in that status for us to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665df887-7fad-4fb7-bd7b-45d5ec367999",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "output = setup_cdc_and_wait(\n",
    "    config={\n",
    "        \"database\": \"graph_rag\", \n",
    "        \"schema\": \"graph_rag\", \n",
    "        \"model_name\": \"graph_rag\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77b7f37-e275-4dad-b50e-b27945a55cc2",
   "metadata": {},
   "source": [
    "### Creating a RelationalAI model\n",
    "\n",
    "A RelationalAI model is the abstraction that defines the data structures for representing the graph. The model is tightly knitted to the data synchronized through the Data Streams already provisioned.\n",
    "\n",
    "To proceed, we shall first define a model named `graph_rag`. Subsequently, we shall define `Entity` and `Relation` model types. Observe how the source of data for each type are tables `nodes` and `edges`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822c920b-7dde-4343-84ac-992b63a20671",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Defining a RelationalAI model named `graph_rag`.\n",
    "rai_model = rai.Model(\"graph_rag\", dry_run=False)\n",
    "snowflake_model = Snowflake(rai_model)\n",
    "\n",
    "# Defining an `Entity` type. A `Entity` is a node in the graph.\n",
    "Entity = rai_model.Type(\"Entity\", source=\"graph_rag.graph_rag.nodes\")\n",
    "\n",
    "# Defining a `Relation` type. A `Relation` is an edge in the graph.\n",
    "# Note how we attach `src` and `dst` properties in the `Relation`, \n",
    "# indicatiing the source and destination entities, respectivelly.\n",
    "Relation = rai_model.Type(\"Relation\", source=\"graph_rag.graph_rag.edges\")\n",
    "Relation.define(\n",
    "    src=(Entity, \"src_node_id\", \"id\"), \n",
    "    dst=(Entity, \"dst_node_id\", \"id\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e86de26-e3fb-4708-8a38-091ea1f08db6",
   "metadata": {},
   "source": [
    "#### (Optional) Exploring the RelationalAI model data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6325f504-699c-4308-8586-34d811350eb2",
   "metadata": {},
   "source": [
    "Having created our model, let's take a look at how we can inspect the properties of the types created. Also, we shall fetch some data to inspect how they are being represented in our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6597ac8b-cfd3-44f7-b7c4-19b95584b5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Get the list of properties of each defined type.\n",
    "print(\n",
    "    f\"\"\"\n",
    "    Entity.known_properties(): {Entity.known_properties()}\n",
    "    Relation.known_properties(): {Relation.known_properties()}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8162ad69-7e29-4f82-bb05-fe7a12e126d9",
   "metadata": {},
   "source": [
    "Querying our model to retrieve all `Entity` instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14da7261-3d58-4b34-8e11-efd367295a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "with rai_model.query() as select:\n",
    "    entity = Entity()\n",
    "    response = select.distinct(entity, entity.id, entity.type)\n",
    "model_entities = response.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679ef773-e974-4bae-8a0f-bb209947e739",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_entities.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dace2db5-1724-4255-bdab-687ba84d40f6",
   "metadata": {},
   "source": [
    "We can also count how many `Entity` instances we have in our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6ee245-b689-41e3-a273-b1b8b23d8948",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "with rai_model.query() as select:\n",
    "    entity = Entity()\n",
    "    response = select(aggregates.count(entity))\n",
    "print(\"Entity count:\", response.results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581a36e6-7294-425a-aa5c-5324a2c3664f",
   "metadata": {},
   "source": [
    "Repeating the same for `Relations`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b775dae-9a5a-40cc-86d2-c9c3bb96e9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "with rai_model.query() as select:\n",
    "    relation = Relation()\n",
    "    response = select.distinct(relation, relation.src_node_id, relation.dst_node_id, relation.type)\n",
    "model_relations = response.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f9e1ce-263a-460c-a1bc-40e4b0854e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_relations.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d14917-733c-48b5-97bc-876f77b52ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "with rai_model.query() as select:\n",
    "    relation = Relation()\n",
    "    response = select(aggregates.count(relation))\n",
    "print(\"Relation count:\", response.results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0826045-0037-4da0-9d2b-e4be9ac8b0f2",
   "metadata": {},
   "source": [
    "### Creating the graph, computing community identifiers and visualizing the graph\n",
    "\n",
    "We shall now use the RelationalAI model we have defined previously and get a graph out of it.\n",
    "\n",
    "First, we shall define a `Graph` data structure out of our RelationalAI model.\n",
    "\n",
    "Subsequentyl, we shall execute the [Louvain](https://relational.ai/docs/reference/python/std/graphs/Compute/louvain/) community detection algorithm on the graph to identify communities.\n",
    "\n",
    "Finally, we shall visualize the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810dde9a-cd90-4e34-a44a-e0c7a33f412a",
   "metadata": {},
   "outputs": [],
   "source": [
    "community_color_map = get_random_color_map(communities_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d6c692-236c-4047-b626-d0de69faaf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Creating a graph representation of our model.\n",
    "graph = Graph(model=rai_model, undirected=True)\n",
    "\n",
    "# Applying the Louvain community detection on the model.\n",
    "with rai_model.rule():\n",
    "    entity = Entity()\n",
    "    community_id = graph.compute.louvain(node=entity, max_levels=5, max_sweeps=10, level_tolerance=1e-2, sweep_tolerance=1e-4)\n",
    "    entity.set(community_id=community_id)\n",
    "\n",
    "with rai_model.rule():\n",
    "    relation = Relation()\n",
    "    graph.Node.extend(Entity, id=Entity.id, corpus_id=str(Entity.corpus_id), type=Entity.type, community_id=Entity.community_id)\n",
    "    graph.Edge.add(from_=relation.src, to=relation.dst, corpus_id=str(relation.corpus_id), type=relation.type) # label=concat(relation.src.id, relation.dst.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55d81d7-b2d6-4a51-910f-10c867e130c3",
   "metadata": {},
   "source": [
    "Note that computations are defined and are applied lazily. \n",
    "\n",
    "For example, let's see how many communities we were able to identify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24dc7ac-20e8-4ad0-9086-9f452d5a07d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "with rai_model.query() as select:\n",
    "    entity = Entity()\n",
    "    response = select(aggregates.count(entity.community_id))\n",
    "print(\"Communities count:\", response.results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8900637b-e198-483c-87c5-d56d941cedb9",
   "metadata": {},
   "source": [
    "Let's also visualize the graph, making sure that each community has a unique color:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaef1a1-e732-4647-83e9-d8e07a5c155f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = graph.visualize(\n",
    "    three=False, \n",
    "    graph_height=750, \n",
    "    show_node_label=True, \n",
    "    show_edge_label=True, \n",
    "    layout_algorithm_active = True, \n",
    "    layout_algorithm = \"hierarchicalRepulsion\", \n",
    "    avoid_overlap = 1.0,\n",
    "    style={\n",
    "        \"node\": {\n",
    "            \"label\": lambda n: f\"{n.get('id')} ({n.get('type')})\", \n",
    "            \"color\": lambda n: community_color_map.get(n[\"community_id\"], \"black\"), \n",
    "            \"size\": 30,\n",
    "            \"border_color\": \"white\",\n",
    "            \"border_size\": 1,\n",
    "            \"hover\": lambda n: f\"{n.get('id')} (type: {n.get('type')}, community: {n.get('community_id')})\"\n",
    "        }, \n",
    "        \"edge\": {\n",
    "            \"label\": lambda e: e.get(\"type\"), \n",
    "            \"color\": \"grey\", \n",
    "            \"hover\": lambda e: e.get(\"type\")\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "vis.display(inline=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e22fd6-8c33-4ccc-b20e-953522b36617",
   "metadata": {},
   "source": [
    "## Community-based summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56d3f92-fcd6-4210-adf7-8d51e54528a7",
   "metadata": {},
   "source": [
    "Having identified graph communities, we shall now produce summaries out of the text of all corpus items in a community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef70b789-f2b2-4770-8323-72b8aef9ce63",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "with rai_model.query() as select:\n",
    "    entity = Entity()\n",
    "    response = select(alias(entity.id, \"id\"), alias(entity.community_id, \"community_id\"), alias(entity.corpus_id, \"corpus_id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd8c473-bee4-48f8-bbf6-2fb8993c4fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = response.results\n",
    "results_df.sort_values(by=[\"community_id\", \"corpus_id\"]).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdb6bee-ef30-48c9-b45b-0e613c8b51b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a (community, corpus-id) multi-index.\n",
    "communities_count_df = results_df.groupby(by=[\"community_id\", \"corpus_id\"]).count().rename(columns={\"id\": \"entities_count\"}).sort_index()\n",
    "\n",
    "# Convert the multi index to a dict.\n",
    "index = communities_count_df.index.to_flat_index()\n",
    "d = {}\n",
    "for x, y in index:\n",
    "    d.setdefault(x, []).append(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9d1d92-b262-436e-a13d-0e95fe422575",
   "metadata": {},
   "source": [
    "For each community, we are producing a summary of all corpus items of this community, utilizing a Snowflake LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0498664-4703-4b58-bd2f-c911890fa15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "execute_statement(\n",
    "    session=session, \n",
    "    statement=f\"TRUNCATE TABLE community_summary\"\n",
    ")\n",
    "\n",
    "# Summarize all corpus items of a community.\n",
    "for k, v in d.items():\n",
    "    corpus_ids = \", \".join([str(i) for i in v])\n",
    "    logger.info(f\"Producing summarized versions of IDs ({corpus_ids}) for community {k}\")\n",
    "    try:\n",
    "        execute_statement(\n",
    "            session=session, \n",
    "            statement=\"\"\"\n",
    "                INSERT INTO community_summary(COMMUNITY_ID, CONTENT)\n",
    "                WITH c AS (\n",
    "                    SELECT \n",
    "                        LISTAGG(content, '\\n\\n') WITHIN GROUP(ORDER BY id) AS content \n",
    "                    FROM \n",
    "                        CORPUS\n",
    "                    WHERE \n",
    "                        id IN ({CORPUS_IDS})\n",
    "                )\n",
    "                SELECT \n",
    "                    {COMMUNITY_ID} AS community_id\n",
    "                    , PARSE_JSON(LLM_EXTRACT_JSON(r.response)):answer AS response\n",
    "                FROM \n",
    "                    c\n",
    "                JOIN TABLE(LLM_SUMMARIZE('llama3-70b', c.content)) AS r;\n",
    "            \"\"\", \n",
    "            parameters={\n",
    "                \"COMMUNITY_ID\": str(k), \n",
    "                \"CORPUS_IDS\": corpus_ids\n",
    "            }\n",
    "        )\n",
    "    except Exception as error:\n",
    "        logger.error(f\"Error producing summarized versions of IDs ({corpus_ids}) for community {k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba1e648-5a79-47c1-bfa0-61b521cebb1d",
   "metadata": {},
   "source": [
    "## Question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4285dd-15a9-4c55-b397-e59457def762",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Describe in detail the connection between Samuel Altman and Elon Musk, if one exists.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38f77d8-1a4a-4ab7-abb9-17f0caab4a80",
   "metadata": {},
   "source": [
    "### Querying with community summaries as context\n",
    "\n",
    "Using a window of concatenated community summaries and asking the LLM if the question can be asked from evidence in the context window.\n",
    "\n",
    "LLM calls: `#community summaries / window`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14608b47-eb49-4a0f-817e-a16f22df977e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# The previous-before-last parameter of the procedure call is the summarization window i.e. how many per-community summaries to include as context in the answer.\n",
    "# A smaller value safeguards that we will not exceed the LLM token limit, whereas a larger one provides richer context to the LLM.\n",
    "execute_statement(\n",
    "    session=session, \n",
    "    statement=\"\"\"\n",
    "        CALL LLM_ANSWER_SUMMARIES('llama3-70b', 30, '{QUESTION}');\n",
    "    \"\"\", \n",
    "    parameters={\n",
    "        \"QUESTION\": question\n",
    "    }\n",
    ")\n",
    "\n",
    "# Gather results.\n",
    "answer = execute_statement(\n",
    "    session=session, \n",
    "    statement=\"\"\"\n",
    "        SELECT \n",
    "            * \n",
    "        FROM \n",
    "            TABLE(result_scan(last_query_id()));\n",
    "    \"\"\"\n",
    ")[0][0]\n",
    "\n",
    "print(f\"\"\"\n",
    "    Q: {question}\n",
    "    A: {answer}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8ed855-1ef3-4fb0-b9c2-bcd79029f19e",
   "metadata": {},
   "source": [
    "#### Visualizing the graph again\n",
    "\n",
    "This time, we are highlighting the entities mentioned in the answer to validate against the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721afca9-b839-45a8-8e45-f8b204f2c37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_of_interest = [\"Samuel Harris Altman\", \"Elon Musk\", \"OpenAI\"]\n",
    "\n",
    "vis = graph.visualize(\n",
    "    three=False, \n",
    "    graph_height=1000, \n",
    "    show_node_label=True, \n",
    "    show_edge_label=True, \n",
    "    layout_algorithm_active = True, \n",
    "    layout_algorithm = \"hierarchicalRepulsion\", \n",
    "    avoid_overlap = 1.0,\n",
    "    style={\n",
    "        \"node\": {\n",
    "            \"label\": lambda n: f\"{n.get('id')} ({n.get('type')})\", \n",
    "            \"color\": lambda n: community_color_map.get(n[\"community_id\"], \"black\"), \n",
    "            \"size\": lambda n: 60 if n.get('id') in entities_of_interest else 30,\n",
    "            \"border_color\":  lambda n: \"black\" if n.get('id') in entities_of_interest else \"white\",\n",
    "            \"border_size\": lambda n: 3 if n.get('id') in entities_of_interest else 1,\n",
    "            \"hover\": lambda n: f\"{n.get('id')} (type: {n.get('type')}, community: {n.get('community_id')})\"\n",
    "        }, \n",
    "        \"edge\": {\n",
    "            \"label\": lambda e: e.get(\"type\"), \n",
    "            \"color\": \"grey\", \n",
    "            \"hover\": lambda e: e.get(\"type\")\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "vis.display(inline=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ab0b7e-e389-45e0-9266-92dcbc737573",
   "metadata": {},
   "source": [
    "#### Verify that the entities are connected in the graph\n",
    "\n",
    "Testing the reachability between entities `Elon Musk` and `Samuel Harris Altman` by querying the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09d3c6c-0d31-4b65-9dff-5584c1d88594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can Elon reach Sam?\n",
    "with rai_model.query() as select:\n",
    "    entity_1 = Entity(id=\"Elon Musk\")\n",
    "    entity_2 = Entity(id=\"Samuel Harris Altman\")\n",
    "    with rai_model.match() as reachable:\n",
    "        with rai_model.case():\n",
    "            graph.compute.is_reachable(entity_1, entity_2)\n",
    "            reachable.add(True)\n",
    "        with rai_model.case():\n",
    "            reachable.add(False)\n",
    "    response = select(alias(reachable, \"connected\"))\n",
    "print(f\"Are Elon and Sam connected? {response.results['connected'][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecbdc00-74aa-4372-a038-5a07332d004e",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
